{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fac031a-df9e-4e09-a534-696712aecf8f",
   "metadata": {},
   "source": [
    "## References:\n",
    "* https://flask-sqlalchemy.readthedocs.io/en/stable/\n",
    "* https://docs.sqlalchemy.org/en/20/orm/inheritance.html#concrete-table-inheritance\n",
    "* https://docs.sqlalchemy.org/en/20/_modules/examples/performance/bulk_inserts.html\n",
    "* https://docs.sqlalchemy.org/en/20/orm/large_collections.html#bulk-insert-of-new-items\n",
    "* https://docs.sqlalchemy.org/en/20/orm/extensions/asyncio.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549210ef-e66e-4461-9dd3-7a1a1f1d04f7",
   "metadata": {},
   "source": [
    "## Refactoring notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b18cfc-7e7e-431a-847f-2765019ef6c4",
   "metadata": {},
   "source": [
    "- The relationship between a frequency severity model and the input premium file is missing\n",
    "- The back-relationship were missing for handling properly session.delete(histolossfile) :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12788cb3-ca8f-4534-97b2-4ea3fca4e51b",
   "metadata": {},
   "source": [
    "```\n",
    "class Analysis(CommonMixin, Base):\n",
    "    \"\"\"Represents an analysis entity.\"\"\"\n",
    "\n",
    "    id: Mapped[int] = mapped_column(primary_key=True)\n",
    "    client_id: Mapped[int] = mapped_column(ForeignKey(\"client.id\"), nullable=False)\n",
    "    client: Mapped[\"Client\"] = relationship(back_populates=\"analyses\")\n",
    "\n",
    "    histolossfiles: Mapped[List[\"HistoLossFile\"]] = relationship(\n",
    "        secondary=lambda: analysis_histolossfile_table, back_populates=\"analyses\"\n",
    "    )\n",
    "    modelfiles: Mapped[List[\"ModelFile\"]] = relationship(\n",
    "        secondary=lambda: analysis_modelfile_table, back_populates=\"analyses\"\n",
    "    )\n",
    "\n",
    "    class HistoLossFile(CommonMixin, Base):\n",
    "\n",
    "    analyses: Mapped[List[Analysis]] = relationship(\n",
    "        secondary=lambda: analysis_histolossfile_table, back_populates=\"histolossfiles\"\n",
    "    )\n",
    "\n",
    "  class ModelFile(CommonMixin, Base):\n",
    "        \"\"\"Base class for model files.\"\"\"\n",
    "    \n",
    "        id: Mapped[int] = mapped_column(primary_key=True)\n",
    "        model_type: Mapped[str] = mapped_column(String(50), nullable=False)\n",
    "        years_simulated: Mapped[int] = mapped_column(nullable=False)\n",
    "    \n",
    "        client_id: Mapped[int] = mapped_column(ForeignKey(\"client.id\"), nullable=False)\n",
    "        client: Mapped[\"Client\"] = relationship(back_populates=\"modelfiles\")\n",
    "    \n",
    "        yearlosses: Mapped[List[\"ModelYearLoss\"]] = relationship(\n",
    "            back_populates=\"modelfile\",\n",
    "            cascade=\"all, delete-orphan\",\n",
    "        )\n",
    "    \n",
    "        analyses: Mapped[List[Analysis]] = relationship(\n",
    "            secondary=lambda: analysis_modelfile_table, back_populates=\"modelfiles\"\n",
    "        )\n",
    "```\n",
    "\n",
    "- Cascade delete, all for client-analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faff1d73-22cd-4002-ba5e-5df747f6a353",
   "metadata": {},
   "source": [
    "```\n",
    "class Client(CommonMixin, Base): \"\"\"Represents a client entity.\"\"\"\n",
    "\n",
    "  id: Mapped[int] = mapped_column(primary_key=True)\n",
    "  name: Mapped[str] = mapped_column(String(50), nullable=False)\n",
    "\n",
    "  analyses: Mapped[List[\"Analysis\"]] = relationship(\n",
    "      back_populates=\"client\", cascade=\"all, delete-orphan\"\n",
    "  )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e162c4ef-7963-421d-98ee-8eb5d82d2283",
   "metadata": {},
   "source": [
    "- The Pydantic classes FrequencyInput and SeverityInput need to be reviewed and refactored\n",
    "- The attribute treshold is missing in the FrequencyModel class\n",
    "- Start frequency and severity models parameters with index 0\n",
    "- The threshold of frequency and severity models is that of the related frequency_severity_model => Remove attribute threshold from severity model\n",
    "- Use ModelType in polymorphic identity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fd4bb3-3492-4dd5-95f9-bf2380809997",
   "metadata": {},
   "source": [
    "## Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cd7511-27f7-4d3a-bbd8-464a1aa82cea",
   "metadata": {},
   "source": [
    "### Enumerations and Dataclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "df406879-7e64-4964-b0c1-52e604df0842",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class ModelType(Enum):\n",
    "    \"\"\"Defines the supported loss models.\"\"\"\n",
    "\n",
    "    EMPIRICAL = \"empirical\"\n",
    "    # FREQUENCY_SEVERITY = \"frequency_severity\"\n",
    "    FREQUENCY_SEVERITY = \"frequencyseveritymodel\"\n",
    "    COMPOSITE_FREQUENCY_SEVERITY = \"composite_frequency_severity\"\n",
    "    EXPOSURE_BASED = \"exposure_based\"\n",
    "\n",
    "\n",
    "class DistributionType(Enum):\n",
    "    \"\"\"Defines the supported statistical distributions.\"\"\"\n",
    "\n",
    "    POISSON = \"poisson\"\n",
    "    NEGATIVE_BINOMIAL = \"negative_binomial\"\n",
    "    PARETO = \"pareto\"\n",
    "\n",
    "\n",
    "class LossType(Enum):\n",
    "    \"\"\"Defines the loss types.\"\"\"\n",
    "\n",
    "    CAT = \"cat\"\n",
    "    NON_CAT = \"non_cat\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DistributionInput:\n",
    "    \"\"\"\n",
    "    Configuration for a statistical distribution.\n",
    "\n",
    "    Attributes:\n",
    "        dist: The distribution type (enum).\n",
    "        params: Parameters specific to the distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    dist: DistributionType\n",
    "    params: list[float]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b719d63-a33c-486c-9310-942158abbf19",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e5ecd867-201c-4729-8d42-2bfa52208eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen distribution: DistributionType.PARETO\n",
      "Parameters: [1000, 2]\n",
      "Mean draw: 1994\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "from scipy.stats import poisson, nbinom, pareto\n",
    "\n",
    "\n",
    "# Main function to generate model year loss\n",
    "def get_modelyearloss_frequency_severity(\n",
    "    frequency_input: DistributionInput,\n",
    "    severity_input: DistributionInput,\n",
    "    simulated_years: int,\n",
    "    modelfile_id: int,\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Generate loss data for a frequency-severity model over a number of simulated years.\n",
    "\n",
    "    Args:\n",
    "        frequency_input (DistributionInput): Distribution defining the frequency of events per year.\n",
    "        severity_input (DistributionInput): Distribution defining the severity of each event.\n",
    "        simulated_years (int): Number of years to simulate.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with the following keys:\n",
    "            - \"year\": List of years for each loss event.\n",
    "            - \"day\": Random day of the year for each loss.\n",
    "            - \"loss\": Calculated loss values.\n",
    "            - \"loss_type\": Type of loss (e.g., catastrophic or non-catastrophic).\n",
    "    \"\"\"\n",
    "    frequencies = generate_frequencies(frequency_input, simulated_years)\n",
    "    loss_count = frequencies.sum()\n",
    "    years = generate_years(frequencies)\n",
    "    days = generate_days(loss_count)\n",
    "    losses = generate_losses_from_parametric_dist(severity_input, loss_count)\n",
    "    loss_types = generate_loss_types(loss_count)\n",
    "    modelfile_ids = np.repeat(modelfile_id, loss_count)\n",
    "\n",
    "    modelyearloss = pl.DataFrame(\n",
    "        {\n",
    "            \"year\": years,\n",
    "            \"day\": days,\n",
    "            \"loss\": losses,\n",
    "            \"loss_type\": loss_types,\n",
    "            \"modelfile_id\": modelfile_ids,\n",
    "        }\n",
    "    )\n",
    "    return modelyearloss\n",
    "\n",
    "\n",
    "def generate_frequencies(\n",
    "    frequency_input: DistributionInput,\n",
    "    size: int,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate a list of event frequencies based on a specified distribution.\n",
    "\n",
    "    Args:\n",
    "        frequency_input (DistributionInput): The distribution and parameters for frequency generation.\n",
    "        size (int): Number of values to generate.\n",
    "\n",
    "    Returns:\n",
    "        list[int]: A list of event frequencies for each simulated year.\n",
    "    \"\"\"\n",
    "    frequencies = get_sample_from_dist(frequency_input, size)\n",
    "    return frequencies\n",
    "\n",
    "\n",
    "def generate_years(frequencies: list[int]) -> list[int]:\n",
    "    \"\"\"\n",
    "    Generate a list of years for loss events based on event frequencies.\n",
    "\n",
    "    Args:\n",
    "        frequencies (list[int]): A list where each element represents the number of events in a year.\n",
    "\n",
    "    Returns:\n",
    "        list[int]: A list of years, repeated according to their respective frequencies.\n",
    "    \"\"\"\n",
    "    years = [\n",
    "        year for year, freq in enumerate(frequencies, start=1) for _ in range(freq)\n",
    "    ]\n",
    "    return years\n",
    "\n",
    "\n",
    "def generate_days(size: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate random days of the year for loss events.\n",
    "\n",
    "    Args:\n",
    "        size (int): Number of days to generate.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: An array of random integers representing days (1 to 365).\n",
    "    \"\"\"\n",
    "    days = np.random.randint(1, 366, size)\n",
    "    return days\n",
    "\n",
    "\n",
    "def generate_loss_types(size: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate random loss types (catastrophic or non-catastrophic) for events.\n",
    "\n",
    "    Args:\n",
    "        size (int): Number of loss types to generate.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: An array of randomly chosen loss types (catastrophic or non-catastrophic).\n",
    "    \"\"\"\n",
    "    loss_types = np.random.choice([LossType.CAT.value, LossType.NON_CAT.value], size)\n",
    "    return loss_types\n",
    "\n",
    "\n",
    "def generate_losses_from_parametric_dist(\n",
    "    severity_input: DistributionInput,\n",
    "    loss_count: int,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates a set of rounded loss values from a parametric distribution.\n",
    "\n",
    "    Args:\n",
    "        severity_input (DistributionInput): Parameters defining the severity distribution.\n",
    "        loss_count (int): The number of loss values to generate.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: An array of rounded loss values.\n",
    "    \"\"\"\n",
    "    sample = get_sample_from_dist(severity_input, loss_count)\n",
    "    sample_to_int = sample.astype(int)\n",
    "    return sample_to_int\n",
    "\n",
    "\n",
    "def get_sample_from_dist(\n",
    "    distribution_input: DistributionInput, size: int\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generate a sample from the specified distribution.\n",
    "\n",
    "    Args:\n",
    "        distribution_input (DistributionInput): An object containing the distribution type\n",
    "            (e.g., Poisson, Negative Binomial, Pareto) and its associated parameters.\n",
    "        size (int): The number of samples to generate.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: An array of samples drawn from the specified distribution.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the distribution type is not supported.\n",
    "    \"\"\"\n",
    "    dist = distribution_input.dist\n",
    "    params = distribution_input.params\n",
    "\n",
    "    match dist:\n",
    "        case DistributionType.POISSON:\n",
    "            return poisson.rvs(mu=params[0], size=size)\n",
    "        case DistributionType.NEGATIVE_BINOMIAL:\n",
    "            return nbinom.rvs(n=params[0], p=params[1], size=size)\n",
    "        case DistributionType.PARETO:\n",
    "            return pareto.rvs(scale=params[0], b=params[1], size=size)\n",
    "        case _:\n",
    "            raise ValueError(f\"Unsupported distribution: {dist}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "distribution_input = DistributionInput(dist=DistributionType.PARETO, params=[1000, 2])\n",
    "sample = get_sample_from_dist(distribution_input, size=1_000_000)\n",
    "\n",
    "# Output for debugging\n",
    "print(f\"Chosen distribution: {distribution_input.dist}\")\n",
    "print(f\"Parameters: {distribution_input.params}\")\n",
    "print(f\"Mean draw: {sample.mean().astype(int)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429868bf-6f9f-46d9-bba1-e368c895637b",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8d9d8b5b-5d6f-475b-a706-08d80e849f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration = 0.5023344000001089\n",
      "Average Loss = 1998.8750349839074\n",
      "Frequency = 4.00184\n",
      "shape: (400_184, 5)\n",
      "┌────────┬─────┬──────┬───────────┬──────────────┐\n",
      "│ year   ┆ day ┆ loss ┆ loss_type ┆ modelfile_id │\n",
      "│ ---    ┆ --- ┆ ---  ┆ ---       ┆ ---          │\n",
      "│ i64    ┆ i32 ┆ i64  ┆ str       ┆ i64          │\n",
      "╞════════╪═════╪══════╪═══════════╪══════════════╡\n",
      "│ 1      ┆ 301 ┆ 1322 ┆ cat       ┆ 1            │\n",
      "│ 1      ┆ 111 ┆ 3506 ┆ cat       ┆ 1            │\n",
      "│ 1      ┆ 43  ┆ 1942 ┆ non_cat   ┆ 1            │\n",
      "│ 2      ┆ 114 ┆ 1076 ┆ cat       ┆ 1            │\n",
      "│ 2      ┆ 263 ┆ 2390 ┆ non_cat   ┆ 1            │\n",
      "│ …      ┆ …   ┆ …    ┆ …         ┆ …            │\n",
      "│ 99998  ┆ 33  ┆ 2730 ┆ cat       ┆ 1            │\n",
      "│ 99998  ┆ 162 ┆ 1195 ┆ non_cat   ┆ 1            │\n",
      "│ 99999  ┆ 116 ┆ 1329 ┆ cat       ┆ 1            │\n",
      "│ 99999  ┆ 335 ┆ 1936 ┆ cat       ┆ 1            │\n",
      "│ 100000 ┆ 3   ┆ 1237 ┆ cat       ┆ 1            │\n",
      "└────────┴─────┴──────┴───────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "frequency_input = DistributionInput(\n",
    "    dist=DistributionType.POISSON,\n",
    "    params=[4],\n",
    ")\n",
    "\n",
    "severity_input = DistributionInput(\n",
    "    dist=DistributionType.PARETO,\n",
    "    params=[1000, 2],\n",
    ")\n",
    "\n",
    "simulated_years = 100_000\n",
    "modelfile_id = 1\n",
    "start = time.perf_counter()\n",
    "modelyearloss = get_modelyearloss_frequency_severity(\n",
    "    frequency_input,\n",
    "    severity_input,\n",
    "    simulated_years,\n",
    "    modelfile_id,\n",
    ")\n",
    "print(f\"Duration = {time.perf_counter() - start}\")\n",
    "print(f\"Average Loss = {modelyearloss[\"loss\"].mean()}\")\n",
    "print(f\"Frequency = {len(modelyearloss[\"loss\"]) / simulated_years}\")\n",
    "print(modelyearloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d846cfc-7582-4e2d-9e4d-0c700173f432",
   "metadata": {},
   "source": [
    "## Backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c65c16-cc0e-422f-9e1c-814d0e028952",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fa3ca2d7-9b01-49a0-9eb9-17a2ac38dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from sqlalchemy import desc, insert, select, text\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "from sqlalchemy.orm import Session\n",
    "\n",
    "from database import (\n",
    "    Analysis,\n",
    "    Client,\n",
    "    HistoLossFile,\n",
    "    ModelFile,\n",
    "    ModelYearLoss,\n",
    "    FrequencyModel,\n",
    "    SeverityModel,\n",
    "    FrequencySeverityModel,\n",
    "    session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d98ebb8-59f9-4f83-9997-60d5b5f0c1ba",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f06779b1-2cfc-440e-a796-68faed7d1994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 'AXA' added successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create a client\n",
    "def add_client(session, client_name):\n",
    "    \"\"\"\n",
    "    Add a new client to the database.\n",
    "\n",
    "    Args:\n",
    "        session (Session): The SQLAlchemy session to use.\n",
    "        client_name (str): The name of the client to be added.\n",
    "\n",
    "    Raises:\n",
    "        SQLAlchemyError: If a database error occurs.\n",
    "        Exception: If any other unexpected error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a new client\n",
    "        client = Client(name=client_name)\n",
    "\n",
    "        # Add the client to the session\n",
    "        session.add(client)\n",
    "\n",
    "        # Commit the transaction\n",
    "        session.commit()\n",
    "        print(f\"Client '{client_name}' added successfully.\")\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        session.rollback()\n",
    "        print(f\"Database error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "    except Exception as e:\n",
    "        session.rollback()\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cdccaa70-36f4-4c0a-8145-43e0e2f6a233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an analysis and associate it with a client\n",
    "def add_analysis_to_client(session, client_id):\n",
    "    \"\"\"\n",
    "    Create an analysis and associates it with a client.\n",
    "\n",
    "    Args:\n",
    "        session (Session): The SQLAlchemy session to use.\n",
    "        client_id (int): The ID of the client to associate the analysis with.\n",
    "\n",
    "    Raises:\n",
    "        SQLAlchemyError: If a database error occurs.\n",
    "        Exception: If any other unexpected error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Retrieve the client\n",
    "        client = session.get_one(Client, client_id)\n",
    "\n",
    "        # Create a new analysis\n",
    "        analysis = Analysis()\n",
    "\n",
    "        # Associate the analysis with the client\n",
    "        client.analyses.append(analysis)\n",
    "\n",
    "        # Commit the transaction\n",
    "        session.commit()\n",
    "        print(\"Analysis added successfully\")\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        session.rollback()\n",
    "        print(f\"Database error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "    except Exception as e:\n",
    "        session.rollback()\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2c6fcaff-1103-438d-a0de-0202fc93e312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a historical loss file and associate it with a client and an analysis\n",
    "def create_historical_loss_file(session: Session, analysis_id: int):\n",
    "    \"\"\"\n",
    "    Create a historical loss file and associates it with a client and an analysis.\n",
    "\n",
    "    Args:\n",
    "        session (Session): The SQLAlchemy session to use.\n",
    "        analysis_id (int): The ID of the analysis to associate the historical loss file with.\n",
    "\n",
    "    Raises:\n",
    "        SQLAlchemyError: If a database error occurs.\n",
    "        Exception: If any other unexpected error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Retrieve the analysis and the associated client\n",
    "        analysis = session.get(Analysis, analysis_id)\n",
    "        if not analysis:\n",
    "            raise ValueError(f\"Analysis with ID {analysis_id} not found.\")\n",
    "        client = analysis.client\n",
    "\n",
    "        # Create the historical loss file\n",
    "        histolossfile = HistoLossFile()\n",
    "\n",
    "        # Associate the historical loss file with the client and analysis\n",
    "        client.histolossfiles.append(histolossfile)\n",
    "        analysis.histolossfiles.append(histolossfile)\n",
    "\n",
    "        # Commit the transaction\n",
    "        session.commit()\n",
    "        print(\"Historical loss file added successfully\")\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        session.rollback()\n",
    "        print(f\"Database error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "    except Exception as e:\n",
    "        session.rollback()\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "34b984f2-74c8-4c0e-9220-34dcb6865016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a frequency-severity loss model\n",
    "def create_frequency_severity_model(\n",
    "    session: Session,\n",
    "    analysis_id: int,\n",
    "    lossfile_id: int,\n",
    "    frequency_input: DistributionInput,\n",
    "    severity_input: DistributionInput,\n",
    "    years_simulated: int,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Create a frequency-severity model and persists related data in the database.\n",
    "\n",
    "    Args:\n",
    "        session (Session): The SQLAlchemy session to use for database operations.\n",
    "        analysis_id (int): ID of the analysis to associate the model with.\n",
    "        lossfile_id (int): ID of the loss file to associate the model with.\n",
    "        frequency_input (DistributionInput): Input parameters for the frequency model.\n",
    "        severity_input (DistributionInput): Input parameters for the severity model.\n",
    "        years_simulated (int): Number of years simulated for the model.\n",
    "\n",
    "    Raises:\n",
    "        SQLAlchemyError: If a database error occurs during the process.\n",
    "        Exception: If an unexpected error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch analysis and ensure it exists\n",
    "        analysis = session.get(Analysis, analysis_id)\n",
    "        if not analysis:\n",
    "            raise ValueError(f\"Analysis with ID {analysis_id} not found.\")\n",
    "        client_id = analysis.client_id\n",
    "\n",
    "        # Create frequency and severity models\n",
    "        start_time = time.perf_counter()\n",
    "        frequencymodel = FrequencyModel(\n",
    "            **{\n",
    "                f\"parameter_{i}\": param\n",
    "                for i, param in enumerate(frequency_input.params)\n",
    "            }\n",
    "        )\n",
    "        severitymodel = SeverityModel(\n",
    "            **{f\"parameter_{i}\": param for i, param in enumerate(severity_input.params)}\n",
    "        )\n",
    "\n",
    "        # Create the frequency-severity model\n",
    "        modelfile = FrequencySeverityModel(\n",
    "            model_type=\"frequencyseveritymodel\",\n",
    "            threshold=threshold,\n",
    "            years_simulated=years_simulated,\n",
    "            lossfile_id=lossfile_id,\n",
    "            frequencymodel=frequencymodel,\n",
    "            severitymodel=severitymodel,\n",
    "        )\n",
    "\n",
    "        # Link the model to the analysis and the client\n",
    "        analysis.client.modelfiles.append(modelfile)\n",
    "        analysis.modelfiles.append(modelfile)\n",
    "        print(\n",
    "            f\"Time to create model file in the session: {time.perf_counter() - start_time:.2f} seconds\"\n",
    "        )\n",
    "\n",
    "        # Flush to get modelfile ID\n",
    "        start_time = time.perf_counter()\n",
    "        session.flush()\n",
    "        modelfile_id = modelfile.id\n",
    "        print(\n",
    "            f\"Time to flush the session: {time.perf_counter() - start_time:.2f} seconds\"\n",
    "        )\n",
    "\n",
    "        # Generate year loss data\n",
    "        start_time = time.perf_counter()\n",
    "        modelyearloss = get_modelyearloss_frequency_severity(\n",
    "            frequency_input, severity_input, years_simulated, modelfile_id\n",
    "        )\n",
    "        print(\n",
    "            f\"Time to generate year loss data: {time.perf_counter() - start_time:.2f} seconds\"\n",
    "        )\n",
    "\n",
    "        # Insert records into the database\n",
    "        start_time = time.perf_counter()\n",
    "        session.execute(insert(ModelYearLoss), modelyearloss.to_dicts())\n",
    "        print(\n",
    "            f\"Time to insert year loss records into database: {time.perf_counter() - start_time:.2f} seconds\"\n",
    "        )\n",
    "\n",
    "        # Commit the transaction\n",
    "        start_time = time.perf_counter()\n",
    "        session.commit()\n",
    "        print(\n",
    "            f\"Time to commit transaction: {time.perf_counter() - start_time:.2f} seconds\"\n",
    "        )\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        session.rollback()\n",
    "        print(f\"Database error occurred: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        session.rollback()\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e75de26d-c2f5-4b3c-909a-55954c478327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client 'AXA' added successfully.\n",
      "Analysis added successfully\n",
      "Historical loss file added successfully\n"
     ]
    }
   ],
   "source": [
    "# Create a client, an analysis and a historical loss file\n",
    "add_client(session, client_name=\"AXA\")\n",
    "add_analysis_to_client(session, client_id=1)\n",
    "create_historical_loss_file(session, analysis_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9547ed47-ae04-4b2c-8f2e-b6bb26f4ddcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to create model file in the session: 0.01 seconds\n",
      "Time to flush the session: 0.00 seconds\n",
      "Time to generate year loss data: 0.44 seconds\n",
      "Time to insert year loss records into database: 18.64 seconds\n",
      "Time to commit transaction: 0.04 seconds\n",
      "Total Duration = 19.143806499996572\n"
     ]
    }
   ],
   "source": [
    "# Create a frequency-severity model\n",
    "start = time.perf_counter()\n",
    "create_frequency_severity_model(\n",
    "    session,\n",
    "    analysis_id=1,\n",
    "    lossfile_id=1,\n",
    "    frequency_input=DistributionInput(\n",
    "        dist=DistributionType.POISSON,\n",
    "        params=[3, 0, 0, 0, 0],\n",
    "    ),\n",
    "    severity_input=DistributionInput(\n",
    "        dist=DistributionType.PARETO,\n",
    "        params=[1000, 2, 0, 0, 0],\n",
    "    ),\n",
    "    years_simulated=100_000,\n",
    ")\n",
    "\n",
    "duration = time.perf_counter() - start\n",
    "print(f\"Total Duration = {duration}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "45bc9f3b-aa6e-4009-ae3a-5b39aaee821a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database error occurred: (psycopg2.errors.ForeignKeyViolation) ERREUR:  UPDATE ou DELETE sur la table « histolossfile » viole la contrainte de clé étrangère « frequencyseveritymodel_lossfile_id_fkey » de la table « frequencyseveritymodel »\n",
      "DETAIL:  La clé (id)=(1) est toujours référencée à partir de la table « frequencyseveritymodel ».\n",
      "\n",
      "[SQL: DELETE FROM histolossfile WHERE histolossfile.id = %(id)s]\n",
      "[parameters: {'id': 1}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/gkpj)\n"
     ]
    },
    {
     "ename": "IntegrityError",
     "evalue": "(psycopg2.errors.ForeignKeyViolation) ERREUR:  UPDATE ou DELETE sur la table « histolossfile » viole la contrainte de clé étrangère « frequencyseveritymodel_lossfile_id_fkey » de la table « frequencyseveritymodel »\nDETAIL:  La clé (id)=(1) est toujours référencée à partir de la table « frequencyseveritymodel ».\n\n[SQL: DELETE FROM histolossfile WHERE histolossfile.id = %(id)s]\n[parameters: {'id': 1}]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mForeignKeyViolation\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\Documents\\mywebapps\\train_sqla\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1967\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32m~\\Documents\\mywebapps\\train_sqla\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:941\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 941\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mForeignKeyViolation\u001b[0m: ERREUR:  UPDATE ou DELETE sur la table « histolossfile » viole la contrainte de clé étrangère « frequencyseveritymodel_lossfile_id_fkey » de la table « frequencyseveritymodel »\nDETAIL:  La clé (id)=(1) est toujours référencée à partir de la table « frequencyseveritymodel ».\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[150], line 46\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m         session\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m---> 46\u001b[0m \u001b[43mcreate_historical_loss_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhistolossfile_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[150], line 29\u001b[0m, in \u001b[0;36mcreate_historical_loss_file\u001b[1;34m(session, histolossfile_id)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Delete the file\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     session\u001b[38;5;241m.\u001b[39mdelete(histolossfile)\n\u001b[1;32m---> 29\u001b[0m     \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe historical loss file has been deleted.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SQLAlchemyError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\Documents\\mywebapps\\train_sqla\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:2028\u001b[0m, in \u001b[0;36mSession.commit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trans \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2026\u001b[0m     trans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autobegin_t()\n\u001b[1;32m-> 2028\u001b[0m \u001b[43mtrans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_to_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<string>:2\u001b[0m, in \u001b[0;36mcommit\u001b[1;34m(self, _to_root)\u001b[0m\n",
      "File \u001b[1;32m~\\Documents\\mywebapps\\train_sqla\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\state_changes.py:139\u001b[0m, in \u001b[0;36m_StateChange.declare_states.<locals>._go\u001b[1;34m(fn, self, *arg, **kw)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_state \u001b[38;5;241m=\u001b[39m _StateChangeStates\u001b[38;5;241m.\u001b[39mCHANGE_IN_PROGRESS\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 139\u001b[0m     ret_value \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\mywebapps\\train_sqla\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:1313\u001b[0m, in \u001b[0;36mSessionTransaction.commit\u001b[1;34m(self, _to_root)\u001b[0m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SessionTransactionState\u001b[38;5;241m.\u001b[39mPREPARED:\n\u001b[0;32m   1312\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expect_state(SessionTransactionState\u001b[38;5;241m.\u001b[39mPREPARED):\n\u001b[1;32m-> 1313\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnested:\n\u001b[0;32m   1316\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m conn, trans, should_commit, autoclose \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\n\u001b[0;32m   1317\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connections\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[0;32m   1318\u001b[0m     ):\n",
      "File \u001b[1;32m<string>:2\u001b[0m, in \u001b[0;36m_prepare_impl\u001b[1;34m(self)\u001b[0m\n",
      "File \u001b[1;32m~\\Documents\\mywebapps\\train_sqla\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\state_changes.py:139\u001b[0m, in \u001b[0;36m_StateChange.declare_states.<locals>._go\u001b[1;34m(fn, self, *arg, **kw)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_state \u001b[38;5;241m=\u001b[39m _StateChangeStates\u001b[38;5;241m.\u001b[39mCHANGE_IN_PROGRESS\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 139\u001b[0m     ret_value \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\mywebapps\\train_sqla\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:1288\u001b[0m, in \u001b[0;36mSessionTransaction._prepare_impl\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39m_is_clean():\n\u001b[0;32m   1287\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1288\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mFlushError(\n\u001b[0;32m   1291\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOver 100 subsequent flushes have occurred within \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1292\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msession.commit() - is an after_flush() hook \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1293\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreating new objects?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1294\u001b[0m     )\n",
      "File \u001b[1;32m~\\Documents\\mywebapps\\train_sqla\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:4352\u001b[0m, in \u001b[0;36mSession.flush\u001b[1;34m(self, objects)\u001b[0m\n\u001b[0;32m   4350\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   4351\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flushing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 4352\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flush\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjects\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4353\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   4354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flushing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\mywebapps\\train_sqla\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:4487\u001b[0m, in \u001b[0;36mSession._flush\u001b[1;34m(self, objects)\u001b[0m\n\u001b[0;32m   4484\u001b[0m     transaction\u001b[38;5;241m.\u001b[39mcommit()\n\u001b[0;32m   4486\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m-> 4487\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msafe_reraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   4488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransaction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_capture_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\mywebapps\\train_sqla\\.venv\\Lib\\site-packages\\sqlalchemy\\util\\langhelpers.py:146\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[1;34m(self, type_, value, traceback)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc_value\u001b[38;5;241m.\u001b[39mwith_traceback(exc_tb)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exc_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# remove potential circular references\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\mywebapps\\train_sqla\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\session.py:4448\u001b[0m, in \u001b[0;36mSession._flush\u001b[1;34m(self, objects)\u001b[0m\n\u001b[0;32m   4446\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_on_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   4447\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 4448\u001b[0m     \u001b[43mflush_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4449\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   4450\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_warn_on_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\mywebapps\\train_sqla\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\unitofwork.py:466\u001b[0m, in \u001b[0;36mUOWTransaction.execute\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    465\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m rec \u001b[38;5;129;01min\u001b[39;00m topological\u001b[38;5;241m.\u001b[39msort(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdependencies, postsort_actions):\n\u001b[1;32m--> 466\u001b[0m         \u001b[43mrec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\mywebapps\\train_sqla\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\unitofwork.py:679\u001b[0m, in \u001b[0;36mDeleteAll.execute\u001b[1;34m(self, uow)\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[38;5;129m@util\u001b[39m\u001b[38;5;241m.\u001b[39mpreload_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlalchemy.orm.persistence\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    678\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, uow):\n\u001b[1;32m--> 679\u001b[0m     \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreloaded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morm_persistence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete_obj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m        \u001b[49m\u001b[43muow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstates_for_mapper_hierarchy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[43muow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\mywebapps\\train_sqla\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\persistence.py:193\u001b[0m, in \u001b[0;36mdelete_obj\u001b[1;34m(base_mapper, states, uowtransaction)\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    189\u001b[0m     delete \u001b[38;5;241m=\u001b[39m _collect_delete_commands(\n\u001b[0;32m    190\u001b[0m         base_mapper, uowtransaction, table, states_to_delete\n\u001b[0;32m    191\u001b[0m     )\n\u001b[1;32m--> 193\u001b[0m     \u001b[43m_emit_delete_statements\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbase_mapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43muowtransaction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelete\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (\n\u001b[0;32m    202\u001b[0m     state,\n\u001b[0;32m    203\u001b[0m     state_dict,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    206\u001b[0m     update_version_id,\n\u001b[0;32m    207\u001b[0m ) \u001b[38;5;129;01min\u001b[39;00m states_to_delete:\n\u001b[0;32m    208\u001b[0m     mapper\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_delete(mapper, connection, state)\n",
      "File \u001b[1;32m~\\Documents\\mywebapps\\train_sqla\\.venv\\Lib\\site-packages\\sqlalchemy\\orm\\persistence.py:1465\u001b[0m, in \u001b[0;36m_emit_delete_statements\u001b[1;34m(base_mapper, uowtransaction, mapper, table, delete)\u001b[0m\n\u001b[0;32m   1461\u001b[0m         connection\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[0;32m   1462\u001b[0m             statement, del_objects, execution_options\u001b[38;5;241m=\u001b[39mexecution_options\n\u001b[0;32m   1463\u001b[0m         )\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1465\u001b[0m     c \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1466\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdel_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecution_options\u001b[49m\n\u001b[0;32m   1467\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1469\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m need_version_id:\n\u001b[0;32m   1470\u001b[0m         only_warn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\mywebapps\\train_sqla\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1418\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[0;32m   1416\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1417\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\mywebapps\\train_sqla\\.venv\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py:515\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[1;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[1;32m--> 515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\mywebapps\\train_sqla\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1640\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[1;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[0;32m   1628\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[38;5;241m=\u001b[39m execution_options\u001b[38;5;241m.\u001b[39mget(\n\u001b[0;32m   1629\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompiled_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_compiled_cache\n\u001b[0;32m   1630\u001b[0m )\n\u001b[0;32m   1632\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[0;32m   1633\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[0;32m   1634\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1638\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[0;32m   1639\u001b[0m )\n\u001b[1;32m-> 1640\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1645\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1651\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_execute(\n\u001b[0;32m   1654\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1655\u001b[0m         elem,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1659\u001b[0m         ret,\n\u001b[0;32m   1660\u001b[0m     )\n",
      "File \u001b[1;32m~\\Documents\\mywebapps\\train_sqla\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1846\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exec_insertmany_context(dialect, context)\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1846\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\mywebapps\\train_sqla\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1986\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1983\u001b[0m     result \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39m_setup_result_proxy()\n\u001b[0;32m   1985\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1986\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1987\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1988\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\Documents\\mywebapps\\train_sqla\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2355\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[0;32m   2353\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[0;32m   2354\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception\u001b[38;5;241m.\u001b[39mwith_traceback(exc_info[\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   2356\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2357\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\mywebapps\\train_sqla\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1967\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[1;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[0;32m   1965\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1966\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1967\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1968\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[0;32m   1972\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[0;32m   1973\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1974\u001b[0m         cursor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1978\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[0;32m   1979\u001b[0m     )\n",
      "File \u001b[1;32m~\\Documents\\mywebapps\\train_sqla\\.venv\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:941\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 941\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIntegrityError\u001b[0m: (psycopg2.errors.ForeignKeyViolation) ERREUR:  UPDATE ou DELETE sur la table « histolossfile » viole la contrainte de clé étrangère « frequencyseveritymodel_lossfile_id_fkey » de la table « frequencyseveritymodel »\nDETAIL:  La clé (id)=(1) est toujours référencée à partir de la table « frequencyseveritymodel ».\n\n[SQL: DELETE FROM histolossfile WHERE histolossfile.id = %(id)s]\n[parameters: {'id': 1}]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)"
     ]
    }
   ],
   "source": [
    "# Delete a historical loss file\n",
    "\n",
    "def create_historical_loss_file(\n",
    "    session: Session,\n",
    "    histolossfile_id: int,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Delete a historical loss file from the database.\n",
    "\n",
    "    Args:\n",
    "        session: The SQLAlchemy session to use for database operations.\n",
    "        histolossfile_id (int): The ID of the historical loss file to delete.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the historical loss file with the given ID is not found.\n",
    "        SQLAlchemyError: If a database error occurs.\n",
    "        Exception: For any other unexpected errors.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch the historical loss file\n",
    "        histolossfile = session.get(HistoLossFile, histolossfile_id)\n",
    "        if not histolossfile:\n",
    "            raise ValueError(\n",
    "                f\"Historical loss file with ID {histolossfile_id} not found.\"\n",
    "            )\n",
    "\n",
    "        # Delete the file\n",
    "        session.delete(histolossfile)\n",
    "        session.commit()\n",
    "        print(f\"The historical loss file has been deleted.\")\n",
    "\n",
    "    except SQLAlchemyError as e:\n",
    "        session.rollback()\n",
    "        print(f\"Database error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "    except Exception as e:\n",
    "        session.rollback()\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "    finally:\n",
    "        session.close()\n",
    "\n",
    "\n",
    "create_historical_loss_file(session, histolossfile_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3c99b32e-7e13-4f31-a694-760b0e24adba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = session.scalars(select(FrequencyModel)).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "40da31df-8625-40b9-9ffa-0a0e19d9584d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FrequencyModel(id=4)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "01d037d5-4c79-47eb-9cdd-072a18231ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.delete(fm)\n",
    "    session.commit()\n",
    "except Exception as e:\n",
    "    session.rollback()\n",
    "    print(f\"An error occured: {e}\")\n",
    "    raise\n",
    "finally:\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9089e6-e918-47e4-94cf-0560d2325a4e",
   "metadata": {},
   "source": [
    "# USE ASYNCIO??? (ASK CHATGPT)\n",
    "\n",
    "# DELETE A FREQUENCY SEVERITY MODEL, A FREQUENCY SOLO, A SEVERITY SOLO. PROBLEM WITH THE DELETION CURRENTLY\n",
    "\n",
    "# TRANSFORM SCRIPTS INTO FUNCTIONS\n",
    "\n",
    "# THEN CREATE JIRA SPECIFIC ISSUES\n",
    "\n",
    "# THEN WORKSHOP WITH ANTOINE B TO REVIEW CHANGES LIKE THOSE IN PYDANTIC FOR FREQUENCYINPUT SEVERITYINPUT ETC\n",
    "\n",
    "# THEN DO UI FOR TRAIN_SQLA FOR  ENGINE ONLY FOR ACTUARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0d4b84-481c-4ab5-87a4-9eda08108598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153442c4-d952-48af-a3bd-c598cc0cc6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
